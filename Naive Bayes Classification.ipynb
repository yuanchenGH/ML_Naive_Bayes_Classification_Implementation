{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Yuan Chen\n",
    "ID: 9082757429"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def count_char(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        count = Counter(f.read().lower())\n",
    "    return count\n",
    "\n",
    "def reorder_dict(dict):\n",
    "    char_order = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', ' ']\n",
    "    ordered_dict = {k: dict[k] for k in char_order}\n",
    "    return ordered_dict\n",
    "\n",
    "def dict_2_array(dict):\n",
    "    item_list = list(dict.values())\n",
    "    return np.array(item_list)\n",
    "\n",
    "def read_data(L, train_size):\n",
    "    y = []\n",
    "    N = 0\n",
    "    char_count_each_language = {}\n",
    "    for l in L:\n",
    "        total_count = {}\n",
    "        for i in range(train_size):\n",
    "            N += 1\n",
    "            y.append(l)\n",
    "            filename = 'languageID\\\\' + l + str(i) + '.txt'\n",
    "            char_count = count_char(filename)\n",
    "            total_count = Counter(total_count) + Counter(char_count)\n",
    "        total_count2 = reorder_dict(total_count)\n",
    "        char_count_each_language[l] = total_count2\n",
    "    y = np.array(y)\n",
    "    return y, char_count_each_language\n",
    "    \n",
    "def get_prior(y, alpha):\n",
    "    unique_lang = set(y)\n",
    "    prob_prior = dict(e=0, j=0, s=0)\n",
    "    for l in unique_lang:\n",
    "        prob_prior[l] = round((np.count_nonzero(y == l)+alpha)/(len(y)+3*alpha), 3)\n",
    "    return prob_prior\n",
    "\n",
    "def get_class_conditional_prob(char_count_dict, alpha):\n",
    "    chars = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', ' ']\n",
    "    char_prob_list = []\n",
    "    n = 0\n",
    "    for i in char_count_dict:\n",
    "        n += char_count_dict[i]\n",
    "    for c in chars:\n",
    "        p = (char_count_dict[c] + alpha)/(n+27*alpha)\n",
    "        char_prob_list.append(p)\n",
    "    return char_prob_list\n",
    "\n",
    "def get_likelihood(x, conditional_prob):\n",
    "    p = conditional_prob\n",
    "    likelihood = 0\n",
    "    for idx, count in enumerate(x):\n",
    "        likelihood += count*np.log(p[idx])\n",
    "    return(likelihood)\n",
    "\n",
    "def test(filename, prior, conditional_prob_en, conditional_prob_jp, conditional_prob_spa):\n",
    "    L = ['e', 'j', 's']\n",
    "    count_vec = count_char(filename)\n",
    "    count_vec = reorder_dict(count_vec)\n",
    "    x = dict_2_array(count_vec)\n",
    "    likelihood_en = get_likelihood(x, conditional_prob_en)\n",
    "    likelihood_jp = get_likelihood(x, conditional_prob_jp)\n",
    "    likelihood_spa = get_likelihood(x, conditional_prob_spa)\n",
    "    posteriors = [np.log(prior['e'])+likelihood_en, np.log(prior['j'])+likelihood_jp, np.log(prior['s'])+likelihood_spa]\n",
    "    max_val = max(posteriors)\n",
    "    idx = posteriors.index(max_val)\n",
    "    return L[idx]\n",
    "\n",
    "def batch_test(prior, conditional_prob_en, conditional_prob_jp, conditional_prob_spa):\n",
    "    L = ['e', 'j', 's']\n",
    "    y = []\n",
    "    y_pred = []\n",
    "    for l in L:\n",
    "        for i in range(10):\n",
    "            y.append(l)\n",
    "            filename = 'languageID\\\\' + l + str(i) + '.txt'\n",
    "            y_pred.append(test(filename, prior, conditional_prob_en, conditional_prob_jp, conditional_prob_spa))\n",
    "    return y, y_pred\n",
    "#             print(l+str(i+10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "L = ['e', 'j', 's']\n",
    "train_size = 10\n",
    "alpha = 0.5\n",
    "\n",
    "y, char_count_each_language = read_data(L, train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'e': 0.333, 'j': 0.333, 's': 0.333}\n"
     ]
    }
   ],
   "source": [
    "#1\n",
    "prior = get_prior(y, alpha)\n",
    "print(prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conditional proability of English samples:  [0.0601685114819098, 0.011134974392863043, 0.021509995043779945, 0.021972575582355856, 0.1053692383941847, 0.018932760614571286, 0.017478936064761277, 0.047216256401784236, 0.055410540227986124, 0.001420783082768875, 0.0037336857756484387, 0.028977366595076822, 0.020518751032545846, 0.057921691723112505, 0.06446390219725756, 0.01675202378985627, 0.0005617049396993227, 0.053824549810011564, 0.06618205848339666, 0.08012555757475633, 0.026664463902197257, 0.009284652238559392, 0.015496448042293078, 0.001156451346439782, 0.013844374690236246, 0.0006277878737815959, 0.1792499586981662]\n"
     ]
    }
   ],
   "source": [
    "#2\n",
    "char_count_en = char_count_each_language['e']\n",
    "char_prob_en = get_class_conditional_prob(char_count_en, alpha)\n",
    " \\print('Conditional proability of English samples: ', char_prob_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conditional proability of Japanese samples:  [0.1317656102589189, 0.010866906600510151, 0.005485866033054963, 0.01722631818022992, 0.06020475907613823, 0.003878542227191726, 0.014011670568503443, 0.03176211607673224, 0.09703343932352633, 0.0023411020650616725, 0.05740941332681086, 0.001432614696530277, 0.03979873510604843, 0.05671057688947902, 0.09116321324993885, 0.0008735455466648031, 0.00010482546559977637, 0.04280373178657535, 0.0421747789929767, 0.056990111464411755, 0.07061742199238269, 0.0002445927530661449, 0.01974212935462455, 3.4941821866592126e-05, 0.01415143785596981, 0.00772214263251686, 0.12344945665466997]\n",
      "\n",
      "Conditional proability of Spanish samples:  [0.10456045141993771, 0.008232863618143134, 0.03752582405722919, 0.039745922111559924, 0.1138108599796491, 0.00860287996053159, 0.0071844839813758445, 0.0045327001942585795, 0.049859702136844375, 0.006629459467793161, 0.0002775122567913416, 0.052943171656748174, 0.02580863988159477, 0.054176559464709693, 0.07249236841293824, 0.02426690512164287, 0.007677839104560451, 0.05929511886774999, 0.06577040485954797, 0.03561407295488884, 0.03370232185254849, 0.00588942678301625, 9.250408559711388e-05, 0.0024976103111220747, 0.007862847275754679, 0.0026826184823163022, 0.16826493170115014]\n"
     ]
    }
   ],
   "source": [
    "#3\n",
    "char_count_jp = char_count_each_language['j']\n",
    "char_prob_jp = get_class_conditional_prob(char_count_jp, alpha)\n",
    "print('Conditional proability of Japanese samples: ', char_prob_jp)\n",
    "\n",
    "print()\n",
    "\n",
    "char_count_spa = char_count_each_language['s']\n",
    "char_prob_spa = get_class_conditional_prob(char_count_spa, alpha)\n",
    "print('Conditional proability of Spanish samples: ', char_prob_spa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bag-of-word counter vector:  [164  32  53  57 311  55  51 140 140   3   6  85  64 139 182  53   3 141\n",
      " 186 225  65  31  47   4  38   2 498]\n",
      "probability vector:  [0.058530510585305104, 0.011563778687066359, 0.01903575876178616, 0.020458993061732787, 0.11083437110834371, 0.019747375911759475, 0.018324141611812846, 0.04999110478562533, 0.04999110478562533, 0.0012453300124533001, 0.0023127557374132716, 0.03042163316135919, 0.022949653086639387, 0.049635296210638676, 0.06493506493506493, 0.01903575876178616, 0.0012453300124533001, 0.05034691336061199, 0.06635829923501156, 0.08023483365949119, 0.023305461661626045, 0.0112079701120797, 0.016900907311866217, 0.0016011385874399574, 0.0136986301369863, 0.000889521437466643, 0.1773705746308486]\n"
     ]
    }
   ],
   "source": [
    "#4\n",
    "filename = 'languageID\\e10.txt'\n",
    "char_count_e10 = count_char(filename)\n",
    "char_count_e10 = reorder_dict(char_count_e10)\n",
    "count_vec = dict_2_array(char_count_e10)\n",
    "prob_vec = get_class_conditional_prob(test_data, alpha)\n",
    "print('bag-of-word counter vector: ', count_vec)\n",
    "print('probability vector: ', prob_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-7841.865447060635 -8771.433079075032 -8467.282044010557\n"
     ]
    }
   ],
   "source": [
    "#5\n",
    "p_en = get_likelihood(count_vec, char_prob_en)\n",
    "p_jp = get_likelihood(count_vec, char_prob_jp)\n",
    "p_spa = get_likelihood(count_vec, char_prob_spa)\n",
    "print(p_en, p_jp, p_spa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e\n"
     ]
    }
   ],
   "source": [
    "#6\n",
    "result = test(filename, prior, char_prob_en, char_prob_jp, char_prob_spa)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels:  ['e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'j', 'j', 'j', 'j', 'j', 'j', 'j', 'j', 'j', 'j', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's'] \n",
      "predictions ['e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'e', 'j', 'j', 'j', 'j', 'j', 'j', 'j', 'j', 'j', 'j', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's']\n"
     ]
    }
   ],
   "source": [
    "#7\n",
    "y, y_pred = batch_test(prior, char_prob_en, char_prob_jp, char_prob_spa)\n",
    "print('Labels: ', y, '\\npredictions', y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s\n"
     ]
    }
   ],
   "source": [
    "#8\n",
    "import random\n",
    "\n",
    "filename = 'languageID\\s16.txt'\n",
    "f = open(filename, 'r')\n",
    "chars = f.read()\n",
    "s = str(chars)\n",
    "s = random.sample(s, len(s))\n",
    "char_count = Counter(s)\n",
    "char_count = reorder_dict(char_count)\n",
    "x = dict_2_array(char_count)\n",
    "likelihood_en = get_likelihood(x, char_prob_en)\n",
    "likelihood_jp = get_likelihood(x, char_prob_jp)\n",
    "likelihood_spa = get_likelihood(x, char_prob_spa)\n",
    "posteriors = [np.log(prior['e'])+likelihood_en, np.log(prior['j'])+likelihood_jp, np.log(prior['s'])+likelihood_spa]\n",
    "max_val = max(posteriors)\n",
    "idx = posteriors.index(max_val)\n",
    "print(L[idx])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
